{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-24T18:46:40.266562Z",
     "end_time": "2023-04-24T18:46:46.911419Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data.data_preparer import DataPreparer\n",
    "from src.predictor.multilayer_perceptron import MultiLayerPerceptronPredictor\n",
    "from src.predictor.neural_network_trainer import NeuralNetworkTrainer\n",
    "from src.data.data_reader import DataReader\n",
    "import os\n",
    "import pandas as pd\n",
    "from tools.RestaurantReviewsDataset import RestaurantReviewsDataset\n",
    "from tools.config_parser import ConfigParser\n",
    "from tools.profiles_manager import ProfilesManager\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "while str(os.getcwd())[-3:] != 'src':  # Execute from src-directory root\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "businesses, reviews, tips = DataReader().read_data()\n",
    "user_profiles_list = ProfilesManager().get_user_profiles_names()\n",
    "\n",
    "\n",
    "def get_trained_models_for_user_profiles(train_test_data_f: tuple, user_profiles_name_f: str):\n",
    "    trained_models_f = []\n",
    "    for model_location in os.scandir(ConfigParser().get_value('predictor_model', 'model_dir')):\n",
    "        trained_model = MultiLayerPerceptronPredictor(input_size=train_test_data_f[0].columns.size, output_size=1)\n",
    "        trained_optimizer = optim.Adam(trained_model.parameters(), lr=0.002)\n",
    "        try:\n",
    "            trained_model.load(trained_optimizer, model_location.path)\n",
    "            if trained_model.user_profiles_location == user_profiles_name_f:\n",
    "                trained_models_f.append((trained_model, trained_optimizer))\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "    return trained_models_f\n",
    "\n",
    "\n",
    "def load_model(model_path: os.PathLike, businesses_f, reviews_f, tips_f):\n",
    "    # Dummy model just to get the user profiles and business profiles\n",
    "    user_profiles_location_f, business_profiles_location_f = MultiLayerPerceptronPredictor.get_profile_names(model_path)\n",
    "\n",
    "    # Load appropriate data\n",
    "    user_profiles_f = ProfilesManager().get_user_profiles(user_profiles_location_f)\n",
    "    business_profiles_f = None if business_profiles_location_f in {\"None\", \"\", \"none\", None} else ProfilesManager().get_business_profiles(business_profiles_location_f)\n",
    "\n",
    "    train_test_data_f = DataPreparer.get_train_test_validate(businesses_f, reviews_f, tips_f, user_profiles_f, business_profiles_f)\n",
    "\n",
    "    # Create valid trained model\n",
    "    trained_model = MultiLayerPerceptronPredictor(input_size=train_test_data_f[0].columns.size, output_size=1)\n",
    "    trained_optimizer = optim.Adam(trained_model.parameters(), lr=0.002)\n",
    "    trained_model.load(trained_optimizer, model_path)\n",
    "\n",
    "    return trained_model, trained_optimizer, train_test_data_f\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T18:55:02.068791Z",
     "end_time": "2023-04-24T18:55:35.169015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dir_entry \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mscandir(ConfigParser()\u001B[38;5;241m.\u001B[39mget_value(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredictor_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m      4\u001B[0m     model_path \u001B[38;5;241m=\u001B[39m dir_entry\u001B[38;5;241m.\u001B[39mpath\n\u001B[1;32m----> 5\u001B[0m     model, _ \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbusinesses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreviews\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtips\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     models_with_loss\u001B[38;5;241m.\u001B[39mappend((model, \u001B[38;5;28mmin\u001B[39m(model\u001B[38;5;241m.\u001B[39mloss_history)))\n",
      "Cell \u001B[1;32mIn[4], line 21\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(model_path, businesses_f, reviews_f, tips_f)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(model_path: os\u001B[38;5;241m.\u001B[39mPathLike, businesses_f, reviews_f, tips_f):\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# Dummy model just to get the user profiles and business profiles\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m     user_profiles_location_f, business_profiles_location_f \u001B[38;5;241m=\u001B[39m \u001B[43mMultiLayerPerceptronPredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_profile_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# Load appropriate data\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     user_profiles_f \u001B[38;5;241m=\u001B[39m ProfilesManager()\u001B[38;5;241m.\u001B[39mget_user_profiles(user_profiles_location_f)\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\src\\predictor\\multilayer_perceptron.py:144\u001B[0m, in \u001B[0;36mMultiLayerPerceptronPredictor.get_profile_names\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_profile_names\u001B[39m(path: os\u001B[38;5;241m.\u001B[39mPathLike) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m--> 144\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_profiles_location\u001B[39m\u001B[38;5;124m'\u001B[39m], checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbusiness_profiles_location\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:809\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    808\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m--> 809\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m    810\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights_only:\n\u001B[0;32m    811\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:1172\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1170\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1171\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1172\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1174\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:1142\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[1;34m(saved_id)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1141\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[1;32m-> 1142\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:1116\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[1;34m(dtype, numel, key, location)\u001B[0m\n\u001B[0;32m   1112\u001B[0m storage \u001B[38;5;241m=\u001B[39m zip_file\u001B[38;5;241m.\u001B[39mget_storage_from_record(name, numel, torch\u001B[38;5;241m.\u001B[39mUntypedStorage)\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_untyped_storage\n\u001B[0;32m   1113\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[0;32m   1114\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[0;32m   1115\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[1;32m-> 1116\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   1117\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1118\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1121\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:217\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[1;34m(storage, location)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[1;32m--> 217\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    219\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:182\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[1;34m(obj, location)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 182\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_cuda_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    184\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice(device):\n",
      "File \u001B[1;32mD:\\Documents\\School\\2de Master\\Thesis\\code\\.venv\\lib\\site-packages\\torch\\serialization.py:166\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[1;34m(location)\u001B[0m\n\u001B[0;32m    163\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_get_device_index(location, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m--> 166\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    167\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    168\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    169\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    170\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    171\u001B[0m device_count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "def get_all_models_with_loss():\n",
    "    models_with_loss_f = []\n",
    "    for dir_entry in os.scandir(ConfigParser().get_value(\"predictor_model\", \"model_dir\")):\n",
    "        model_path = dir_entry.path\n",
    "        model_f, _, train_test_data_f = load_model(model_path, businesses, reviews, tips)\n",
    "        models_with_loss_f.append((model_f, min(model.loss_history), train_test_data_f))\n",
    "\n",
    "\n",
    "models_with_loss = get_all_models_with_loss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T17:25:18.100721Z",
     "end_time": "2023-04-24T17:25:27.333836Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_best_models(n: int = 5):\n",
    "    all_models = get_all_models_with_loss()\n",
    "    return sorted(all_models, key=lambda x: x[1])[:5]\n",
    "\n",
    "best_models = get_best_models(5)\n",
    "for i, (model, loss) in enumerate(best_models):\n",
    "    model.plot_loss_progress(save_location=f\"{i}_loss{loss}.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Old code\n",
    "results = []\n",
    "\n",
    "for model, _, train_test_data in best_models:\n",
    "    logging.info(f\"Testing model with User Profiles: {model.user_profiles_location} and Business Profiles: {model.business_profiles_location}\")\n",
    "    model.eval()  # Prepare layers of model for evaluation\n",
    "    with torch.no_grad():\n",
    "        testX, testY = train_test_data[1], train_test_data[3]\n",
    "\n",
    "        testX = testX.head(500)\n",
    "        testY = testY.head(500)\n",
    "\n",
    "        dl = RestaurantReviewsDataset(testX.to_numpy(), testY.to_numpy())\n",
    "        test_loader = DataLoader(dl, batch_size=500)\n",
    "        for x, y in test_loader:\n",
    "            # Prepare data\n",
    "            x, y = DataPreparer.get_tensor_for_ml(x, y)\n",
    "            # Compute predictions and loss\n",
    "\n",
    "            predictions = model(x)\n",
    "            predictions = predictions.cpu().detach().numpy().squeeze().transpose()\n",
    "            y = y.cpu().detach().numpy().squeeze().transpose()\n",
    "            result = pd.DataFrame(data=[predictions, y]).transpose()\n",
    "            result.columns = ['predicted', 'actual']\n",
    "            result['predicted'] = result['predicted'].transform(lambda x: round(x * 4 + 1))\n",
    "            result['actual'] = result['actual'].transform(lambda x: int(x * 4 + 1))\n",
    "            result['difference'] = abs(result['predicted'] - result['actual'])\n",
    "            results.append(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Histogram of differences between prediction and actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([211., 232.,  49.,   7.,   1.]),\n array([0., 1., 2., 3., 4., 5.]),\n <BarContainer object of 5 artists>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print()\n",
    "print(\"Histogram of differences between prediction and actual:\")\n",
    "plt.hist(result['difference'], bins=[0, 1, 2, 3, 4, 5], align='left', rwidth=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T19:37:05.411881Z",
     "end_time": "2023-04-08T19:37:05.520396Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
